{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Conversational Interface - Chatbot with Claude LLM\n",
    "\n",
    "> *This notebook should work well with the **`Data Science 3.0`** kernel in SageMaker Studio*\n",
    "\n",
    "In this notebook, we will build a chatbot using the Foundation Models (FMs) in Amazon Bedrock. For our use-case we use Claude as our FM for building the chatbot. We use OpenSearch for a vector database to use RAG. We use LangChain as framework to make it all work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Overview\n",
    "\n",
    "This demo shows how using RAG context with the CSA v4.0 security guide for cloud computing will provide more relevant responses compared to using a LLM directly.\n",
    "\n",
    "This solution will demostrate using a vector database with RAG to reduce hallucination and provided context to prompts for better results. First we will call the LLM with no prompt engineering or RAG to see results are generic and not what we are looking for. Next we will add a prompt template using Langchain to improve our prompt. Then we will first lookup results in a vector database to provde better context with our prompt before calling the LLM. Results will now be related to our intended topic. Finally, we will string prompts together as a chat history to provide even more context to our prompts using previous questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Setup our environment and create the boto3 bedrock client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create new client\n",
      "  Using region: us-west-2\n",
      "boto3 Bedrock client successfully created!\n",
      "bedrock-runtime(https://bedrock-runtime.us-west-2.amazonaws.com)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import boto3\n",
    "\n",
    "module_path = \"..\"\n",
    "sys.path.append(os.path.abspath(module_path))\n",
    "from utils import bedrock, print_ww\n",
    "\n",
    "\n",
    "# ---- ⚠️ Un-comment and edit the below lines as needed for your AWS setup ⚠️ ----\n",
    "\n",
    "# os.environ[\"AWS_DEFAULT_REGION\"] = \"<REGION_NAME>\"  # E.g. \"us-east-1\"\n",
    "# os.environ[\"AWS_PROFILE\"] = \"<YOUR_PROFILE>\"\n",
    "# os.environ[\"BEDROCK_ASSUME_ROLE\"] = \"<YOUR_ROLE_ARN>\"  # E.g. \"arn:aws:...\"\n",
    "\n",
    "\n",
    "boto3_bedrock = bedrock.get_bedrock_client(\n",
    "    assumed_role=os.environ.get(\"BEDROCK_ASSUME_ROLE\", None),\n",
    "    region=os.environ.get(\"AWS_DEFAULT_REGION\", None)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup LangChain objects for text LLM with Bedrock and Claude, embeddings model with Bedrock and Amazon Titan embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We will be using the Titan Embeddings Model to generate our Embeddings.\n",
    "from langchain.embeddings import BedrockEmbeddings\n",
    "from langchain.llms.bedrock import Bedrock\n",
    "from langchain.load.dump import dumps\n",
    "\n",
    "# - create the Anthropic Model\n",
    "llm = Bedrock(\n",
    "    model_id=\"anthropic.claude-v2\", client=boto3_bedrock, model_kwargs={\"max_tokens_to_sample\": 1000}\n",
    ")\n",
    "bedrock_embeddings = BedrockEmbeddings(client=boto3_bedrock)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Q&A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Q&A (Basic - without context)\n",
    "\n",
    "We use [CoversationChain](https://python.langchain.com/en/latest/modules/models/llms/integrations/bedrock.html?highlight=ConversationChain#using-in-a-conversation-chain) from LangChain to start the conversation. We also use the [ConversationBufferMemory](https://python.langchain.com/en/latest/modules/memory/types/buffer.html) for storing the messages. We can also get the history as a list of messages (this is very useful in a chat model).\n",
    "\n",
    "Chatbots needs to remember the previous interactions. Conversational memory allows us to do that. There are several ways that we can implement conversational memory. In the context of LangChain, they are all built on top of the ConversationChain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set our initial question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#question=\"What is resource pooling?\"\n",
    "question=\"What are security best practices?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Send question to LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: What are security best practices?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      " Here are some security best practices:\n",
      "\n",
      "- Practice good password hygiene - Use strong, unique passwords and don't reuse passwords across\n",
      "accounts. Use a password manager if needed.\n",
      "\n",
      "- Enable two-factor authentication (2FA) - This adds an extra layer of security beyond just a\n",
      "password. Use it wherever available.\n",
      "\n",
      "- Keep software updated - Install security updates and patches as soon as they are available to fix\n",
      "vulnerabilities.\n",
      "\n",
      "- Be wary of phishing attempts - Don't click links or download attachments from unknown or\n",
      "suspicious sources. Verify legitimacy first.\n",
      "\n",
      "- Use antivirus/antimalware software - Have reputable security software installed and keep it\n",
      "updated to detect and block malware.\n",
      "\n",
      "- Backup your data - Have backups of important data so it can be restored if compromised or lost.\n",
      "Test backups regularly.\n",
      "\n",
      "- Be careful when connecting to public WiFi - Use a VPN or avoid sensitive activities like banking\n",
      "when on public networks.\n",
      "\n",
      "- Don't overshare online - Be cautious about sharing personal info publicly that could aid identity\n",
      "theft. Limit sharing of travel plans or other sensitive info.\n",
      "\n",
      "- Practice safe web browsing - Avoid questionable websites and don't click ads/popups which could\n",
      "spread malware.\n",
      "\n",
      "- Monitor accounts and statements - Watch for any unauthorized charges or activity that could\n",
      "indicate identity theft.\n",
      "\n",
      "- Secure home WiFi - Use strong encryption like WPA2 on your wireless router and a strong router\n",
      "password. Disable WPS.\n",
      "\n",
      "- Encrypt sensitive data - Use full-disk encryption on devices. Encrypt sensitive files/emails if\n",
      "needed.\n",
      "\n",
      "Let me know if you need any clarification or have additional questions!\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "from langchain.llms.bedrock import Bedrock\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "modelId = \"anthropic.claude-v2\"\n",
    "cl_llm = Bedrock(\n",
    "    model_id=modelId,\n",
    "    client=boto3_bedrock,\n",
    "    model_kwargs={\"max_tokens_to_sample\": 1000},\n",
    ")\n",
    "memory = ConversationBufferMemory()\n",
    "conversation = ConversationChain(\n",
    "    llm=cl_llm, verbose=True, memory=memory\n",
    ")\n",
    "\n",
    "try:\n",
    "    \n",
    "    print_ww(conversation.predict(input = question))\n",
    "\n",
    "except ValueError as error:\n",
    "    if  \"AccessDeniedException\" in str(error):\n",
    "        print(f\"\\x1b[41m{error}\\\n",
    "        \\nTo troubeshoot this issue please refer to the following resources.\\\n",
    "         \\nhttps://docs.aws.amazon.com/IAM/latest/UserGuide/troubleshoot_access-denied.html\\\n",
    "         \\nhttps://docs.aws.amazon.com/bedrock/latest/userguide/security-iam.html\\x1b[0m\\n\")      \n",
    "        class StopExecution(ValueError):\n",
    "            def _render_traceback_(self):\n",
    "                pass\n",
    "        raise StopExecution        \n",
    "    else:\n",
    "        raise error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens here? We asked about resource sharing and recieved back a generic response. This is due a standard LangChain template with no prompt engineering. This is due to the fact that the default prompt used by Langchain ConversationChain is not well designed for Claude. An [effective Claude prompt](https://docs.anthropic.com/claude/docs/introduction-to-prompt-design) should contain `\\n\\nHuman:` at the beginning and also contain `\\n\\nAssistant:` in the prompt sometime after the `\\n\\nHuman:` (optionally followed by other text that you want to [put in Claude's mouth](https://docs.anthropic.com/claude/docs/human-and-assistant-formatting#use-human-and-assistant-to-put-words-in-claudes-mouth)). Let's fix this.\n",
    "\n",
    "To learn more about how to write prompts for Claude, check [Anthropic documentation](https://docs.anthropic.com/claude/docs/introduction-to-prompt-design)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Q&A using prompt template (Langchain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LangChain provides several classes and functions to make constructing and working with prompts easy. We are going to use the [PromptTemplate](https://python.langchain.com/en/latest/modules/prompts/getting_started.html) class to construct the prompt from a f-string template. The prompt also uses chat history to provide some context for follow up questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Here are some best practices for security:\n",
      "\n",
      "- Use strong and unique passwords - Don't use the same password across multiple sites. Make\n",
      "passwords long, complex, and hard to guess. Consider using a password manager.\n",
      "\n",
      "- Enable two-factor authentication - Add an extra layer of security by requiring a second step like\n",
      "a code sent to your phone when logging in.\n",
      "\n",
      "- Keep software up-to-date - Install security patches and updates as soon as they are available to\n",
      "fix vulnerabilities.\n",
      "\n",
      "- Be wary of public WiFi - Public networks can expose your data. Use a VPN when connecting.\n",
      "\n",
      "- Use antivirus/anti-malware software - Run reputable security software to detect and block malware.\n",
      "\n",
      "- Back up your data - Regularly back up important data to an external hard drive or cloud storage.\n",
      "This protects against ransomware or hardware failures.\n",
      "\n",
      "- Think before clicking links - Verify the source of links and attachments before clicking to avoid\n",
      "phishing scams. Hover over links to inspect their actual URLs.\n",
      "\n",
      "- Use a firewall - A firewall monitors traffic and blocks potentially malicious connections. Use the\n",
      "firewall provided by your OS/router.\n",
      "\n",
      "- Be cautious on social media - Limit sharing personal information publicly. Check your security\n",
      "settings. Avoid clicking links from strangers.\n",
      "\n",
      "- Monitor financial accounts - Routinely check bank, credit card statements to ensure no\n",
      "unauthorized activity. Set up alerts for large transactions.\n",
      "\n",
      "- Secure your WiFi network - Use WPA2 encryption, a strong password, and disable WPS. Rename the\n",
      "default SSID and hide the network if possible.\n",
      "\n",
      "Does this help summarize some best practices for security? Let me know if you need any clarification\n",
      "or have additional questions!\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# turn verbose to true to see the full logs and documents\n",
    "conversation= ConversationChain(\n",
    "    llm=cl_llm, verbose=False, memory=ConversationBufferMemory() #memory_chain\n",
    ")\n",
    "\n",
    "# langchain prompts do not always work with all the models. This prompt is tuned for Claude\n",
    "claude_prompt = PromptTemplate.from_template(\"\"\"\n",
    "\n",
    "Human: The following is a friendly conversation between a human and an AI.\n",
    "The AI is talkative and provides lots of specific details from its context. If the AI does not know\n",
    "the answer to a question, it truthfully says it does not know.\n",
    "\n",
    "Current conversation:\n",
    "<conversation_history>\n",
    "{history}\n",
    "</conversation_history>\n",
    "\n",
    "Here is the human's next reply:\n",
    "<human_reply>\n",
    "{input}\n",
    "</human_reply>\n",
    "\n",
    "Assistant:\n",
    "\"\"\")\n",
    "\n",
    "conversation.prompt = claude_prompt\n",
    "\n",
    "print_ww(conversation.predict(input=question))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build on the questions\n",
    "\n",
    "Let's ask a question about AWS to see if model can understand previous conversation and provide a response related to resource sharing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Here are some best practices for security in Amazon Web Services (AWS):\n",
      "\n",
      "- Use IAM to manage access - Create individual IAM users with least privilege permissions instead of\n",
      "using the root account. Enable MFA for all users.\n",
      "\n",
      "- Use security groups to restrict access - Security groups act as a firewall controlling access to\n",
      "EC2 instances. Limit ingress and egress rules to only necessary ports and protocols.\n",
      "\n",
      "- Encrypt data in transit and at rest - Use TLS for data in transit. Enable encryption features like\n",
      "EBS encryption for data at rest.\n",
      "\n",
      "- Rotate access keys periodically - The access keys for IAM users should be rotated every 90 days.\n",
      "This limits impact if keys are compromised.\n",
      "\n",
      "- Use CloudTrail to log activity - CloudTrail provides event logs of all API activity for auditing\n",
      "and visibility into account usage.\n",
      "\n",
      "- Enable AWS WAF on public facing apps - The web application firewall helps protect against common\n",
      "web exploits like SQLi, XSS, etc.\n",
      "\n",
      "- Use AWS organizations to centralize management - Organizations allows you to manage multiple AWS\n",
      "accounts together by consolidating billing and applying policies.\n",
      "\n",
      "- Regularly patch and update - Patch operating systems, applications, and AWS services like RDS or\n",
      "Lambda functions to maintain security.\n",
      "\n",
      "- Monitor with tools like GuardDuty - Use intelligent threat detection services to identify unusual\n",
      "account behavior or malicious activity.\n",
      "\n",
      "Let me know if you have any other specific questions around securing workloads, services, or\n",
      "architecture patterns in AWS!\n"
     ]
    }
   ],
   "source": [
    "print_ww(conversation.predict(input=\"How does this work in AWS?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Interactive session using ipywidgets\n",
    "\n",
    "The following utility class allows us to interact with Claude in a more natural way. We write out the question in an input box, and get Claude's answer. We can then continue our conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ipywidgets as ipw\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "class ChatUX:\n",
    "    \"\"\" A chat UX using IPWidgets\n",
    "    \"\"\"\n",
    "    def __init__(self, qa, retrievalChain = False):\n",
    "        self.qa = qa\n",
    "        self.name = None\n",
    "        self.b=None\n",
    "        self.retrievalChain = retrievalChain\n",
    "        self.out = ipw.Output()\n",
    "\n",
    "\n",
    "    def start_chat(self):\n",
    "        print(\"Starting chat bot\")\n",
    "        display(self.out)\n",
    "        self.chat(None)\n",
    "\n",
    "\n",
    "    def chat(self, _):\n",
    "        if self.name is None:\n",
    "            prompt = \"\"\n",
    "        else: \n",
    "            prompt = self.name.value\n",
    "        if 'q' == prompt or 'quit' == prompt or 'Q' == prompt:\n",
    "            print(\"Thank you , that was a nice chat!!\")\n",
    "            return\n",
    "        elif len(prompt) > 0:\n",
    "            with self.out:\n",
    "                thinking = ipw.Label(value=\"Thinking...\")\n",
    "                display(thinking)\n",
    "                try:\n",
    "                    if self.retrievalChain:\n",
    "                        result = self.qa.run({'question': prompt })\n",
    "                    else:\n",
    "                        result = self.qa.run({'input': prompt }) #, 'history':chat_history})\n",
    "                except:\n",
    "                    result = \"No answer\"\n",
    "                thinking.value=\"\"\n",
    "                print_ww(f\"AI:{result}\")\n",
    "                self.name.disabled = True\n",
    "                self.b.disabled = True\n",
    "                self.name = None\n",
    "\n",
    "        if self.name is None:\n",
    "            with self.out:\n",
    "                self.name = ipw.Text(description=\"You:\", placeholder='q to quit')\n",
    "                self.b = ipw.Button(description=\"Send\")\n",
    "                self.b.on_click(self.chat)\n",
    "                display(ipw.Box(children=(self.name, self.b)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test how this works in a longer conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chat = ChatUX(conversation)\n",
    "chat.start_chat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Chatbot with persona"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AI assistant will play the role of a career coach. Role Play Dialogue requires user message to be set in before starting the chat. ConversationBufferMemory is used to pre-populate the dialog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# store previous interactions using ConversationalBufferMemory and add custom prompts to the chat.\n",
    "memory = ConversationBufferMemory()\n",
    "memory.chat_memory.add_user_message(\"You will be acting as a career coach. Your goal is to give career advice to users\")\n",
    "memory.chat_memory.add_ai_message(\"I am a career coach and give career advice\")\n",
    "cl_llm = Bedrock(model_id=\"anthropic.claude-v2\",client=boto3_bedrock)\n",
    "conversation = ConversationChain(\n",
    "     llm=cl_llm, verbose=True, memory=memory\n",
    ")\n",
    "\n",
    "conversation.prompt = claude_prompt\n",
    "\n",
    "print_ww(conversation.predict(input=\"What are the career options in AI?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print_ww(conversation.predict(input=\"What these people really do? Is it fun?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Let's ask a question that is not specialty of this Persona and the model shouldn't answer that question and give a reason for that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "conversation.verbose = False\n",
    "print_ww(conversation.predict(input=\"How to fix my car?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## RAG document processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Copy pdf(s) from S3 to local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#make a local directory and download the CSA v4.0\n",
    "\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "boto3_s3 = boto3.client('s3')\n",
    "boto3_s3.download_file('372228100697-ea-risk-eval-chatbot-input',\n",
    "                        'Security-Guidance-v4.0-9-20-21.pdf',\n",
    "                        'data/Security-Guidance-v4.0-9-20-21.pdf'\n",
    "                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read the files and chunk the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import PyPDFLoader, PyPDFDirectoryLoader\n",
    "\n",
    "loader = PyPDFDirectoryLoader(\"data/\")\n",
    "\n",
    "documents = loader.load()\n",
    "# - in our testing Character split works better with this PDF data set\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    # Set a really small chunk size, just to show.\n",
    "    chunk_size=5000,\n",
    "    chunk_overlap=200,\n",
    ")\n",
    "docs = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Quick test to check the first document chunk before loading into vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    \n",
    "    sample_embedding = np.array(bedrock_embeddings.embed_query(docs[0].page_content))\n",
    "    modelId = bedrock_embeddings.model_id\n",
    "    print(\"Embedding model Id :\", modelId)\n",
    "    print(\"Sample embedding of a document chunk: \", sample_embedding)\n",
    "    print(\"Size of the embedding: \", sample_embedding.shape)\n",
    "\n",
    "except ValueError as error:\n",
    "    if  \"AccessDeniedException\" in str(error):\n",
    "        print(f\"\\x1b[41m{error}\\\n",
    "        \\nTo troubeshoot this issue please refer to the following resources.\\\n",
    "         \\nhttps://docs.aws.amazon.com/IAM/latest/UserGuide/troubleshoot_access-denied.html\\\n",
    "         \\nhttps://docs.aws.amazon.com/bedrock/latest/userguide/security-iam.html\\x1b[0m\\n\")      \n",
    "        class StopExecution(ValueError):\n",
    "            def _render_traceback_(self):\n",
    "                pass\n",
    "        raise StopExecution        \n",
    "    else:\n",
    "        raise error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Create the OpenSearch vector store\n",
    "This only needs to be done once, if you have an existing OpenSearch instance vector store then it can be re-used\n",
    "\n",
    "host can simply be set to your OpenSearch endpoint DNS with port 443 (do not include https)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install -U opensearch-py==2.3.1 langchain==0.0.309 \"pypdf>=3.8,<4\" \\\n",
    "    apache-beam \\\n",
    "    datasets \\\n",
    "    tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import time\n",
    "vector_store_name = 'bedrock-workshop-rag'\n",
    "index_name = \"bedrock-workshop-rag-index\"\n",
    "encryption_policy_name = \"bedrock-workshop-rag-sp\"\n",
    "network_policy_name = \"bedrock-workshop-rag-np\"\n",
    "access_policy_name = 'bedrock-workshop-rag-ap'\n",
    "identity = boto3.client('sts').get_caller_identity()['Arn']\n",
    "\n",
    "aoss_client = boto3.client('opensearchserverless')\n",
    "\n",
    "security_policy = aoss_client.create_security_policy(\n",
    "    name = encryption_policy_name,\n",
    "    policy = json.dumps(\n",
    "        {\n",
    "            'Rules': [{'Resource': ['collection/' + vector_store_name],\n",
    "            'ResourceType': 'collection'}],\n",
    "            'AWSOwnedKey': True\n",
    "        }),\n",
    "    type = 'encryption'\n",
    ")\n",
    "\n",
    "network_policy = aoss_client.create_security_policy(\n",
    "    name = network_policy_name,\n",
    "    policy = json.dumps(\n",
    "        [\n",
    "            {'Rules': [{'Resource': ['collection/' + vector_store_name],\n",
    "            'ResourceType': 'collection'}],\n",
    "            'AllowFromPublic': True}\n",
    "        ]),\n",
    "    type = 'network'\n",
    ")\n",
    "\n",
    "collection = aoss_client.create_collection(name=vector_store_name,type='VECTORSEARCH')\n",
    "\n",
    "while True:\n",
    "    status = aoss_client.list_collections(collectionFilters={'name':vector_store_name})['collectionSummaries'][0]['status']\n",
    "    if status in ('ACTIVE', 'FAILED'): break\n",
    "    time.sleep(10)\n",
    "\n",
    "access_policy = aoss_client.create_access_policy(\n",
    "    name = access_policy_name,\n",
    "    policy = json.dumps(\n",
    "        [\n",
    "            {\n",
    "                'Rules': [\n",
    "                    {\n",
    "                        'Resource': ['collection/' + vector_store_name],\n",
    "                        'Permission': [\n",
    "                            'aoss:CreateCollectionItems',\n",
    "                            'aoss:DeleteCollectionItems',\n",
    "                            'aoss:UpdateCollectionItems',\n",
    "                            'aoss:DescribeCollectionItems'],\n",
    "                        'ResourceType': 'collection'\n",
    "                    },\n",
    "                    {\n",
    "                        'Resource': ['index/' + vector_store_name + '/*'],\n",
    "                        'Permission': [\n",
    "                            'aoss:CreateIndex',\n",
    "                            'aoss:DeleteIndex',\n",
    "                            'aoss:UpdateIndex',\n",
    "                            'aoss:DescribeIndex',\n",
    "                            'aoss:ReadDocument',\n",
    "                            'aoss:WriteDocument'],\n",
    "                        'ResourceType': 'index'\n",
    "                    }],\n",
    "                'Principal': [identity],\n",
    "                'Description': 'Easy data policy'}\n",
    "        ]),\n",
    "    type = 'data'\n",
    ")\n",
    "\n",
    "host = collection['createCollectionDetail']['id'] + '.' + os.environ.get(\"AWS_DEFAULT_REGION\", None) + '.aoss.amazonaws.com:443'\n",
    "print(host)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set this if you previously created the OpenSearch vector database. Create the document search vector object, set the host if you've previously created and populated the vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "host = \"https://9yw7n4vom05uo27uhhw7.us-west-2.aoss.amazonaws.com\"\n",
    "vector_store_name = 'bedrock-workshop-rag'\n",
    "index_name = \"bedrock-workshop-rag-index\"\n",
    "encryption_policy_name = \"bedrock-workshop-rag-sp\"\n",
    "network_policy_name = \"bedrock-workshop-rag-np\"\n",
    "access_policy_name = 'bedrock-workshop-rag-ap'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from opensearchpy import OpenSearch, RequestsHttpConnection, AWSV4SignerAuth\n",
    "from langchain.vectorstores import OpenSearchVectorSearch\n",
    "\n",
    "service = 'aoss'\n",
    "credentials = boto3.Session().get_credentials()\n",
    "auth = AWSV4SignerAuth(credentials, os.environ.get(\"AWS_DEFAULT_REGION\", None), service)\n",
    "\n",
    "docsearch = OpenSearchVectorSearch.from_documents(\n",
    "    docs,\n",
    "    bedrock_embeddings,\n",
    "    opensearch_url=host,\n",
    "    http_auth=auth,\n",
    "    timeout = 100,\n",
    "    use_ssl = True,\n",
    "    verify_certs = True,\n",
    "    connection_class = RequestsHttpConnection,\n",
    "    index_name=index_name,\n",
    "    engine=\"faiss\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### OCR CSA v4.0 using textract to S3. Just an example, don't need to use this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "boto3_textract = boto3.client('textract')\n",
    "\n",
    "#try:\n",
    "    \n",
    "response = boto3_textract.start_document_text_detection(\n",
    "    DocumentLocation={\n",
    "        'S3Object': {\n",
    "            'Bucket': '372228100697-ea-risk-eval-chatbot-input',\n",
    "            'Name': 'Security-Guidance-v4.0-9-20-21.pdf'\n",
    "        }\n",
    "    },\n",
    "    NotificationChannel={\n",
    "        'SNSTopicArn': 'arn:aws:sns:us-west-2:372228100697:AmazonTextract-372228100697-usw2-chat',\n",
    "        'RoleArn': 'arn:aws:iam::372228100697:role/textract-notifications'\n",
    "    },\n",
    "    OutputConfig={\n",
    "        'S3Bucket': '372228100697-ea-risk-eval-chatbot-output'\n",
    "    }\n",
    ")\n",
    "\n",
    "print(response)\n",
    "#except Exception as error:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Chatbot with Context \n",
    "In this use case we will ask the Chatbot to answer question from some external corpus it has likely never seen before. To do this we apply a pattern called RAG (Retrieval Augmented Generation): the idea is to index the corpus in chunks, then look up which sections of the corpus might be relevant to provide an answer by using semantic similarity between the chunks and the question. Finally the most relevant chunks are aggregated and passed as context to the ConversationChain, similar to providing a history.\n",
    "\n",
    "We will take a pdf file and use **Titan Embeddings Model** to create vectors. This vector is then stored in OpenSearch serverless When the chatbot is asked a question, we query OSS with the question and retrieve the text which is semantically closest. This will be our answer. \n",
    "\n",
    "For this demo we are using CSA v4.0 of the Cloud security guidance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Test querying directly against the vector database without using LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Security Guidance v4.0 © Copyright 2021, Cloud Security Alliance. All rights reserved76\n",
      "6.2 Recommendations\n",
      " •Management plane (metastructure) security\n",
      "• Ensure there is strong perimeter security for API gateways and web consoles.\n",
      "• Use strong authentication and MFA.\n",
      "• Maintain tight control of primary account holder/root account credentials and consider \n",
      "dual-authority to access them.\n",
      "• Establishing multiple accounts with your provider will help with account granularity \n",
      "and to limit blast radius (with IaaS and PaaS).\n",
      "• Use separate super administrator and day-to-day administrator accounts instead of root/\n",
      "primary account holder credentials.\n",
      "• Consistently implement least privilege accounts for metastructure access.\n",
      "• This is why you separate development and test accounts with your cloud provider.\n",
      "• Enforce use of MFA whenever available.\n",
      " •Business continuity\n",
      "• Architecture for failure.\n",
      "• Take a risk-based approach to everything. Even when you assume the worst, it doesn’t \n",
      "mean you can afford or need to keep full availability if the worst happens.\n",
      "• Design for high availability within your cloud provider. In IaaS and PaaS this is often easier \n",
      "and more cost effective than the equivalent in traditional infrastructure.\n",
      "• Take advantage of provider-specific features.\n",
      "• Understand provider history, capabilities, and limitations.\n",
      "• Cross-location should always be considered, but beware of costs depending on \n",
      "availability requirements.\n",
      "• Also ensure things like images and asset IDs are converted to work in the \n",
      "different locations.\n",
      "• Business Continuity for metastructure is as important as that for assets.\n",
      "• Prepare for graceful failure in case of a cloud provider outage.\n",
      "• This can include plans for interoperability and portability with other cloud providers \n",
      "or a different region with your current provider.\n",
      "• For super-high-availability applications, start with cross-location BC before attempting \n",
      "cross-provider BC.\n",
      "• Cloud providers, including private cloud, must provide the highest levels of availability \n",
      "and mechanisms for customers/users to manage aspects of their own availability.\n",
      "\n",
      "Reference: data/Security-Guidance-v4.0-9-20-21.pdf\n",
      "Page: 75\n",
      "\n",
      "\n",
      "Security Guidance v4.0 © Copyright 2021, Cloud Security Alliance. All rights reserved76\n",
      "6.2 Recommendations\n",
      " •Management plane (metastructure) security\n",
      "• Ensure there is strong perimeter security for API gateways and web consoles.\n",
      "• Use strong authentication and MFA.\n",
      "• Maintain tight control of primary account holder/root account credentials and consider \n",
      "dual-authority to access them.\n",
      "• Establishing multiple accounts with your provider will help with account granularity \n",
      "and to limit blast radius (with IaaS and PaaS).\n",
      "• Use separate super administrator and day-to-day administrator accounts instead of root/\n",
      "primary account holder credentials.\n",
      "• Consistently implement least privilege accounts for metastructure access.\n",
      "• This is why you separate development and test accounts with your cloud provider.\n",
      "• Enforce use of MFA whenever available.\n",
      " •Business continuity\n",
      "• Architecture for failure.\n",
      "• Take a risk-based approach to everything. Even when you assume the worst, it doesn’t \n",
      "mean you can afford or need to keep full availability if the worst happens.\n",
      "• Design for high availability within your cloud provider. In IaaS and PaaS this is often easier \n",
      "and more cost effective than the equivalent in traditional infrastructure.\n",
      "• Take advantage of provider-specific features.\n",
      "• Understand provider history, capabilities, and limitations.\n",
      "• Cross-location should always be considered, but beware of costs depending on \n",
      "availability requirements.\n",
      "• Also ensure things like images and asset IDs are converted to work in the \n",
      "different locations.\n",
      "• Business Continuity for metastructure is as important as that for assets.\n",
      "• Prepare for graceful failure in case of a cloud provider outage.\n",
      "• This can include plans for interoperability and portability with other cloud providers \n",
      "or a different region with your current provider.\n",
      "• For super-high-availability applications, start with cross-location BC before attempting \n",
      "cross-provider BC.\n",
      "• Cloud providers, including private cloud, must provide the highest levels of availability \n",
      "and mechanisms for customers/users to manage aspects of their own availability.\n",
      "\n",
      "Reference: data/Security-Guidance-v4.0-9-20-21.pdf\n",
      "Page: 75\n",
      "\n",
      "\n",
      "Security Guidance v4.0 © Copyright 2021, Cloud Security Alliance. All rights reserved76\n",
      "6.2 Recommendations\n",
      " •Management plane (metastructure) security\n",
      "• Ensure there is strong perimeter security for API gateways and web consoles.\n",
      "• Use strong authentication and MFA.\n",
      "• Maintain tight control of primary account holder/root account credentials and consider \n",
      "dual-authority to access them.\n",
      "• Establishing multiple accounts with your provider will help with account granularity \n",
      "and to limit blast radius (with IaaS and PaaS).\n",
      "• Use separate super administrator and day-to-day administrator accounts instead of root/\n",
      "primary account holder credentials.\n",
      "• Consistently implement least privilege accounts for metastructure access.\n",
      "• This is why you separate development and test accounts with your cloud provider.\n",
      "• Enforce use of MFA whenever available.\n",
      " •Business continuity\n",
      "• Architecture for failure.\n",
      "• Take a risk-based approach to everything. Even when you assume the worst, it doesn’t \n",
      "mean you can afford or need to keep full availability if the worst happens.\n",
      "• Design for high availability within your cloud provider. In IaaS and PaaS this is often easier \n",
      "and more cost effective than the equivalent in traditional infrastructure.\n",
      "• Take advantage of provider-specific features.\n",
      "• Understand provider history, capabilities, and limitations.\n",
      "• Cross-location should always be considered, but beware of costs depending on \n",
      "availability requirements.\n",
      "• Also ensure things like images and asset IDs are converted to work in the \n",
      "different locations.\n",
      "• Business Continuity for metastructure is as important as that for assets.\n",
      "• Prepare for graceful failure in case of a cloud provider outage.\n",
      "• This can include plans for interoperability and portability with other cloud providers \n",
      "or a different region with your current provider.\n",
      "• For super-high-availability applications, start with cross-location BC before attempting \n",
      "cross-provider BC.\n",
      "• Cloud providers, including private cloud, must provide the highest levels of availability \n",
      "and mechanisms for customers/users to manage aspects of their own availability.\n",
      "\n",
      "Reference: data/Security-Guidance-v4.0-9-20-21.pdf\n",
      "Page: 75\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = question\n",
    "\n",
    "results = docsearch.similarity_search(query, k=3)  # our search query  # return 3 most relevant docs\n",
    "#print(dumps(results, pretty=True))\n",
    "for x in range(len(results)):\n",
    "        print(results[x].page_content + \"\\n\\nReference: \" + str(results[x].metadata['source']) + \"\\nPage: \" + str(results[x].metadata['page']) + \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Query LLM with vector search context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"query\": \"What are security best practices?\",\n",
      "  \"result\": \" Based on the provided context, some security best practices are:\\n\\n- Use strong authentication and multi-factor authentication (MFA) for accessing management planes like API gateways and web consoles. \\n\\n- Maintain tight control over root account credentials and consider requiring dual authority to access them. \\n\\n- Implement least privilege access and separate accounts for administrators versus regular users.\\n\\n- Enforce MFA whenever available.\\n\\n- Establish multiple accounts to limit blast radius. \\n\\n- Separate development, test, and production environments.\\n\\n- Ensure perimeter security for management interfaces.\\n\\n- Take a risk-based approach to availability requirements. \\n\\n- Design for high availability and utilize cloud-provider specific features.\\n\\n- Have business continuity plans for both infrastructure and metastructure.\\n\\n- Prepare for graceful failure and have interoperability/portability plans.\",\n",
      "  \"source_documents\": [\n",
      "    {\n",
      "      \"lc\": 1,\n",
      "      \"type\": \"constructor\",\n",
      "      \"id\": [\n",
      "        \"langchain\",\n",
      "        \"schema\",\n",
      "        \"document\",\n",
      "        \"Document\"\n",
      "      ],\n",
      "      \"kwargs\": {\n",
      "        \"page_content\": \"Security Guidance v4.0 \\u00a9 Copyright 2021, Cloud Security Alliance. All rights reserved76\\n6.2 Recommendations\\n \\u2022Management plane (metastructure) security\\n\\u2022 Ensure there is strong perimeter security for API gateways and web consoles.\\n\\u2022 Use strong authentication and MFA.\\n\\u2022 Maintain tight control of primary account holder/root account credentials and consider \\ndual-authority to access them.\\n\\u2022 Establishing multiple accounts with your provider will help with account granularity \\nand to limit blast radius (with IaaS and PaaS).\\n\\u2022 Use separate super administrator and day-to-day administrator accounts instead of root/\\nprimary account holder credentials.\\n\\u2022 Consistently implement least privilege accounts for metastructure access.\\n\\u2022 This is why you separate development and test accounts with your cloud provider.\\n\\u2022 Enforce use of MFA whenever available.\\n \\u2022Business continuity\\n\\u2022 Architecture for failure.\\n\\u2022 Take a risk-based approach to everything. Even when you assume the worst, it doesn\\u2019t \\nmean you can afford or need to keep full availability if the worst happens.\\n\\u2022 Design for high availability within your cloud provider. In IaaS and PaaS this is often easier \\nand more cost effective than the equivalent in traditional infrastructure.\\n\\u2022 Take advantage of provider-specific features.\\n\\u2022 Understand provider history, capabilities, and limitations.\\n\\u2022 Cross-location should always be considered, but beware of costs depending on \\navailability requirements.\\n\\u2022 Also ensure things like images and asset IDs are converted to work in the \\ndifferent locations.\\n\\u2022 Business Continuity for metastructure is as important as that for assets.\\n\\u2022 Prepare for graceful failure in case of a cloud provider outage.\\n\\u2022 This can include plans for interoperability and portability with other cloud providers \\nor a different region with your current provider.\\n\\u2022 For super-high-availability applications, start with cross-location BC before attempting \\ncross-provider BC.\\n\\u2022 Cloud providers, including private cloud, must provide the highest levels of availability \\nand mechanisms for customers/users to manage aspects of their own availability.\",\n",
      "        \"metadata\": {\n",
      "          \"source\": \"data/Security-Guidance-v4.0-9-20-21.pdf\",\n",
      "          \"page\": 75\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"lc\": 1,\n",
      "      \"type\": \"constructor\",\n",
      "      \"id\": [\n",
      "        \"langchain\",\n",
      "        \"schema\",\n",
      "        \"document\",\n",
      "        \"Document\"\n",
      "      ],\n",
      "      \"kwargs\": {\n",
      "        \"page_content\": \"Security Guidance v4.0 \\u00a9 Copyright 2021, Cloud Security Alliance. All rights reserved76\\n6.2 Recommendations\\n \\u2022Management plane (metastructure) security\\n\\u2022 Ensure there is strong perimeter security for API gateways and web consoles.\\n\\u2022 Use strong authentication and MFA.\\n\\u2022 Maintain tight control of primary account holder/root account credentials and consider \\ndual-authority to access them.\\n\\u2022 Establishing multiple accounts with your provider will help with account granularity \\nand to limit blast radius (with IaaS and PaaS).\\n\\u2022 Use separate super administrator and day-to-day administrator accounts instead of root/\\nprimary account holder credentials.\\n\\u2022 Consistently implement least privilege accounts for metastructure access.\\n\\u2022 This is why you separate development and test accounts with your cloud provider.\\n\\u2022 Enforce use of MFA whenever available.\\n \\u2022Business continuity\\n\\u2022 Architecture for failure.\\n\\u2022 Take a risk-based approach to everything. Even when you assume the worst, it doesn\\u2019t \\nmean you can afford or need to keep full availability if the worst happens.\\n\\u2022 Design for high availability within your cloud provider. In IaaS and PaaS this is often easier \\nand more cost effective than the equivalent in traditional infrastructure.\\n\\u2022 Take advantage of provider-specific features.\\n\\u2022 Understand provider history, capabilities, and limitations.\\n\\u2022 Cross-location should always be considered, but beware of costs depending on \\navailability requirements.\\n\\u2022 Also ensure things like images and asset IDs are converted to work in the \\ndifferent locations.\\n\\u2022 Business Continuity for metastructure is as important as that for assets.\\n\\u2022 Prepare for graceful failure in case of a cloud provider outage.\\n\\u2022 This can include plans for interoperability and portability with other cloud providers \\nor a different region with your current provider.\\n\\u2022 For super-high-availability applications, start with cross-location BC before attempting \\ncross-provider BC.\\n\\u2022 Cloud providers, including private cloud, must provide the highest levels of availability \\nand mechanisms for customers/users to manage aspects of their own availability.\",\n",
      "        \"metadata\": {\n",
      "          \"source\": \"data/Security-Guidance-v4.0-9-20-21.pdf\",\n",
      "          \"page\": 75\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"lc\": 1,\n",
      "      \"type\": \"constructor\",\n",
      "      \"id\": [\n",
      "        \"langchain\",\n",
      "        \"schema\",\n",
      "        \"document\",\n",
      "        \"Document\"\n",
      "      ],\n",
      "      \"kwargs\": {\n",
      "        \"page_content\": \"Security Guidance v4.0 \\u00a9 Copyright 2021, Cloud Security Alliance. All rights reserved76\\n6.2 Recommendations\\n \\u2022Management plane (metastructure) security\\n\\u2022 Ensure there is strong perimeter security for API gateways and web consoles.\\n\\u2022 Use strong authentication and MFA.\\n\\u2022 Maintain tight control of primary account holder/root account credentials and consider \\ndual-authority to access them.\\n\\u2022 Establishing multiple accounts with your provider will help with account granularity \\nand to limit blast radius (with IaaS and PaaS).\\n\\u2022 Use separate super administrator and day-to-day administrator accounts instead of root/\\nprimary account holder credentials.\\n\\u2022 Consistently implement least privilege accounts for metastructure access.\\n\\u2022 This is why you separate development and test accounts with your cloud provider.\\n\\u2022 Enforce use of MFA whenever available.\\n \\u2022Business continuity\\n\\u2022 Architecture for failure.\\n\\u2022 Take a risk-based approach to everything. Even when you assume the worst, it doesn\\u2019t \\nmean you can afford or need to keep full availability if the worst happens.\\n\\u2022 Design for high availability within your cloud provider. In IaaS and PaaS this is often easier \\nand more cost effective than the equivalent in traditional infrastructure.\\n\\u2022 Take advantage of provider-specific features.\\n\\u2022 Understand provider history, capabilities, and limitations.\\n\\u2022 Cross-location should always be considered, but beware of costs depending on \\navailability requirements.\\n\\u2022 Also ensure things like images and asset IDs are converted to work in the \\ndifferent locations.\\n\\u2022 Business Continuity for metastructure is as important as that for assets.\\n\\u2022 Prepare for graceful failure in case of a cloud provider outage.\\n\\u2022 This can include plans for interoperability and portability with other cloud providers \\nor a different region with your current provider.\\n\\u2022 For super-high-availability applications, start with cross-location BC before attempting \\ncross-provider BC.\\n\\u2022 Cloud providers, including private cloud, must provide the highest levels of availability \\nand mechanisms for customers/users to manage aspects of their own availability.\",\n",
      "        \"metadata\": {\n",
      "          \"source\": \"data/Security-Guidance-v4.0-9-20-21.pdf\",\n",
      "          \"page\": 75\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "\n",
    "qa_with_sources = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=docsearch.as_retriever(search_kwargs={'k': 3}),return_source_documents=True)\n",
    "print(dumps(qa_with_sources(query), pretty=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.chains.conversational_retrieval.prompts import CONDENSE_QUESTION_PROMPT\n",
    "\n",
    "print_ww(CONDENSE_QUESTION_PROMPT.template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Query LLM with vector search context and chat history context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn verbose to true to see the full logs and documents\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory_chain = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "qa = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm, \n",
    "    retriever=docsearch.as_retriever(search_kwargs={'k': 3}), \n",
    "    memory=memory_chain,\n",
    "    condense_question_prompt=CONDENSE_QUESTION_PROMPT,\n",
    "    #verbose=True, \n",
    "    chain_type='stuff', # 'refine',\n",
    "    #max_tokens_limit=300\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Query LLM with vector search context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = question\n",
    "print(dumps(qa(query), pretty=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build on that question, provide chat history to LLM for additional context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = \"How does that apply to AWS\"\n",
    "print(dumps(qa(query), pretty=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Interactive Chatbot with Context "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatUX(qa, retrievalChain=True)\n",
    "chat.start_chat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your mileage might vary, but after 2 or 3 questions you will start to get some weird answers. In some cases, even in other languages.\n",
    "This is happening for the same reasons outlined at the beginning of this notebook: the default langchain prompts are not optimal for Claude. \n",
    "In the following cell we are going to set two new prompts: one for the question rephrasing, and one to get the answer from that rephrased question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# turn verbose to true to see the full logs and documents\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.schema import BaseMessage\n",
    "\n",
    "\n",
    "# We are also providing a different chat history retriever which outputs the history as a Claude chat (ie including the \\n\\n)\n",
    "_ROLE_MAP = {\"human\": \"\\n\\nHuman: \", \"ai\": \"\\n\\nAssistant: \"}\n",
    "def _get_chat_history(chat_history):\n",
    "    buffer = \"\"\n",
    "    for dialogue_turn in chat_history:\n",
    "        if isinstance(dialogue_turn, BaseMessage):\n",
    "            role_prefix = _ROLE_MAP.get(dialogue_turn.type, f\"{dialogue_turn.type}: \")\n",
    "            buffer += f\"\\n{role_prefix}{dialogue_turn.content}\"\n",
    "        elif isinstance(dialogue_turn, tuple):\n",
    "            human = \"\\n\\nHuman: \" + dialogue_turn[0]\n",
    "            ai = \"\\n\\nAssistant: \" + dialogue_turn[1]\n",
    "            buffer += \"\\n\" + \"\\n\".join([human, ai])\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                f\"Unsupported chat history format: {type(dialogue_turn)}.\"\n",
    "                f\" Full chat history: {chat_history} \"\n",
    "            )\n",
    "    return buffer\n",
    "\n",
    "# the condense prompt for Claude\n",
    "condense_prompt_claude = PromptTemplate.from_template(\"\"\"{chat_history}\n",
    "\n",
    "Answer only with the new question.\n",
    "\n",
    "\n",
    "Human: How would you ask the question considering the previous conversation: {question}\n",
    "\n",
    "\n",
    "Assistant: Question:\"\"\")\n",
    "\n",
    "# recreate the Claude LLM with more tokens to sample - this provides longer responses but introduces some latency\n",
    "#cl_llm = Bedrock(model_id=\"anthropic.claude-v2\", client=boto3_bedrock, model_kwargs={\"max_tokens_to_sample\": 1000})\n",
    "memory_chain = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "qa = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm, \n",
    "    retriever=docsearch.as_retriever(search_kwargs={'k': 3}),\n",
    "    #retriever=vectorstore_faiss_aws.as_retriever(search_type='similarity', search_kwargs={\"k\": 8}),\n",
    "    memory=memory_chain,\n",
    "    get_chat_history=_get_chat_history,\n",
    "    #return_source_documents=True,\n",
    "    #verbose=True,\n",
    "    condense_question_prompt=condense_prompt_claude, \n",
    "    chain_type='stuff', # 'refine',\n",
    "    #max_tokens_limit=300\n",
    ")\n",
    "\n",
    "# the LLMChain prompt to get the answer. the ConversationalRetrievalChange does not expose this parameter in the constructor\n",
    "qa.combine_docs_chain.llm_chain.prompt = PromptTemplate.from_template(\"\"\"\n",
    "{context}\n",
    "\n",
    "Human: Use at maximum 5 sentences to answer the question inside the <q></q> XML tags. \n",
    "\n",
    "<q>{question}</q>\n",
    "\n",
    "Do not use any XML tags in the answer. If the answer is not in the context say \"Sorry, I don't know as the answer was not found in the context\"\n",
    "\n",
    "Assistant:\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatUX(qa, retrievalChain=True)\n",
    "chat.start_chat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Do some prompt engineering\n",
    "\n",
    "You can \"tune\" your prompt to get more or less verbose answers. For example, try to change the number of sentences, or remove that instruction all-together. You might also need to change the number of `max_tokens_to_sample` (eg 1000 or 2000) to get the full answer."
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
